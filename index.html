<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My NLP Course Portfolio</title>
    <!-- Importing Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Importing Inter font from Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        /* Applying Inter font as the default */
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Simple scroll-padding-top for better navigation */
        html {
            scroll-padding-top: 6rem; /* Adjust based on your nav height */
            scroll-behavior: smooth;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <!-- Header & Navigation Bar -->
    <header class="bg-white shadow-md fixed w-full z-10">
        <nav class="container mx-auto px-6 py-4 flex flex-wrap justify-center sm:justify-between items-center">
            <a href="#" class="text-2xl font-bold text-blue-600 mb-2 sm:mb-0">NLP Portfolio</a>
            <div class="space-x-2 sm:space-x-4 text-center">
                <a href="#home" class="text-gray-600 hover:text-blue-600 font-medium">Home</a>
                <a href="#unit-1" class="text-gray-600 hover:text-blue-600 font-medium">Unit 1</a>
                <a href="#unit-2" class="text-gray-600 hover:text-blue-600 font-medium">Unit 2</a>
                <a href="#unit-3" class="text-gray-600 hover:text-blue-600 font-medium">Unit 3</a>
                <a href="#unit-4" class="text-gray-600 hover:text-blue-600 font-medium">Unit 4</a>
                <a href="#unit-5" class="text-gray-600 hover:text-blue-600 font-medium">Unit 5</a>
            </div>
        </nav>
    </header>

    <!-- Main Content Area -->
    <main class="container mx-auto px-6 pt-32"> <!-- pt-32 to offset fixed header -->

        <!-- Home/Hero Section -->
        <section id="home" class="text-center py-20">
            <h1 class="text-5xl font-bold text-gray-900 mb-4">Natural Language Processing</h1>
            <p class="text-2xl text-gray-700 mb-6">A Course Portfolio for 21CSE356T</p>
            <p class="text-lg text-gray-600 max-w-2xl mx-auto">This website summarizes the key concepts and applications learned across the course, from foundational principles to modern Transformer models.</p>
        </section>

        <!-- Course Content Section -->
        <div class="space-y-16 mb-24">

            <!-- Unit 1: Introduction to NLP -->
            <section id="unit-1" class="bg-white p-8 rounded-xl shadow-lg">
                <h2 class="text-3xl font-bold text-gray-900 mb-6">Unit 1: Introduction to NLP</h2>
                <p class="text-lg text-gray-700 mb-6">This unit established the fundamentals of Natural Language Processing, defining what it is, why it's needed, and the basic steps for processing text.</p>
                <div class="grid md:grid-cols-2 gap-6">
                    <!-- Column 1 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Core Concepts & Pipeline</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>What is NLP:</strong> A field of AI that enables computers to understand and process human language.</li>
                            <li><strong>Why NLP:</strong> Needed to make sense of the vast amount of unstructured text data.</li>
                            <li><strong>NLP Pipeline:</strong>
                                <ul>
                                    <li>1. Morphological/Lexical Analysis (Words)</li>
                                    <li>2. Syntax Analysis (Grammar)</li>
                                    <li>3. Semantic Analysis (Meaning)</li>
                                    <li>4. Discourse (Context)</li>
                                    <li>5. Pragmatics (Interpretation)</li>
                                </ul>
                            </li>
                            <li><strong>Applications:</strong> Spam filtering, search engines, voice assistants, and machine translation.</li>
                        </ul>
                    </div>
                    <!-- Column 2 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Basic Text Processing</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Tokenization:</strong> Splitting text into individual words or tokens.</li>
                            <li><strong>Stemming & Lemmatization:</strong> Reducing words to their root form (e.g., "running" -> "run").</li>
                            <li><strong>POS Tagging:</strong> Assigning parts of speech (noun, verb, adj) to each token.</li>
                            <li><strong>NER:</strong> Named Entity Recognition, or finding labels like "Person" or "Location".</li>
                            <li><strong>N-grams & Language Models:</strong> Using sequences of words (n-grams) to model language probabilistically.</li>
                            <li><strong>Word Representation:</strong> Representing words as vectors that capture their meaning.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Unit 2: Syntax & Semantic Parsing -->
            <section id="unit-2" class="bg-white p-8 rounded-xl shadow-lg">
                <h2 class="text-3xl font-bold text-gray-900 mb-6">Unit 2: Syntax & Semantic Parsing</h2>
                <p class="text-lg text-gray-700 mb-6">This unit dove into how we analyze the grammatical structure of sentences (syntax) and how we formally represent their meaning (semantics).</p>
                <div class="grid md:grid-cols-2 gap-6">
                    <!-- Column 1 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Syntax (Sentence Structure)</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Syntax Parsing:</strong> Analyzing the grammatical structure of a sentence.</li>
                            <li><strong>Constituency Parsing:</strong> Building a "parse tree" that breaks a sentence into nested phrases (e.g., Noun Phrase, Verb Phrase).</li>
                            <li><strong>Dependency Parsing:</strong> Creating a graph showing how words (e.g., subject, object) are grammatically related to each other (their dependencies).</li>
                            <li><strong>Structural Ambiguity:</strong> When a sentence can have multiple valid grammatical structures (e.g., "I saw the man with the binoculars").</li>
                        </ul>
                    </div>
                    <!-- Column 2 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Semantics (Literal Meaning)</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Semantic Parsing:</strong> Converting a natural language sentence into a formal, executable meaning (like an SQL query).</li>
                            <li><strong>Lexical Ambiguity:</strong> When a single word has multiple meanings (e.g., "bank" as a river bank or a financial institution).</li>
                            <li><strong>Word Sense Disambiguation (WSD):</strong> The task of algorithmically choosing the correct meaning of a word based on its context.</li>
                            <li><strong>Pronoun/Anaphora Resolution:</strong> Figuring out what a pronoun ("he", "she", "it") refers to (its "antecedent").</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Unit 3: Semantic & Discourse Analysis -->
            <section id="unit-3" class="bg-white p-8 rounded-xl shadow-lg">
                <h2 class="text-3xl font-bold text-gray-900 mb-6">Unit 3: Semantic & Discourse Analysis</h2>
                <p class="text-lg text-gray-700 mb-6">This unit focused on how computers can understand the *meaning* of language (semantics) and the *flow* of text beyond single sentences (discourse).</p>
                <div class="grid md:grid-cols-2 gap-6">
                    <!-- Column 1 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Semantic Analysis (Meaning)</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Lexical Semantics:</strong> Word-level meaning (synonyms, antonyms, polysemy).</li>
                            <li><strong>Word Senses:</strong> Understanding that words have multiple meanings (Word Sense Disambiguation - WSD).</li>
                            <li><strong>Word Embeddings:</strong> Representing words as vectors (Word2Vec, CBOW, Skip-gram, GloVe).</li>
                            <li><strong>Sentence Meaning:</strong> Identifying "who did what to whom" using Semantic Role Labeling (SRL) and Semantic Frames.</li>
                            <li><strong>Knowledge Representation:</strong> Structuring knowledge formally with Ontologies, Semantic Networks, and Knowledge Graphs.</li>
                        </ul>
                    </div>
                    <!-- Column 2 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Discourse Analysis (Context & Flow)</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Discourse Structure:</strong> Analyzing how sentences and paragraphs are organized to create a coherent whole.</li>
                            <li><strong>Text Coherence:</strong> Identifying the properties that make a text logical and easy to understand.</li>
                            <li><strong>Reference Resolution:</strong> Solving what pronouns ("he", "she", "it") refer to using Coreference and Anaphora Resolution.</li>
                            <li><strong>Key Tasks:</strong> Includes Intent Detection (finding a user's goal) and Paraphrase Extraction (finding alternate phrasings).</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Unit 4: Modern NLP Models & Applications -->
            <section id="unit-4" class="bg-white p-8 rounded-xl shadow-lg">
                <h2 class="text-3xl font-bold text-gray-900 mb-6">Unit 4: Modern NLP Models & Applications</h2>
                <p class="text-lg text-gray-700 mb-6">This unit explored the architectures that power modern NLP, from sequential models to the revolutionary Transformer, and the real-world tasks they solve.</p>
                <div class="grid md:grid-cols-2 gap-6">
                    <!-- Column 1 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Core Architectures</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>RNN & LSTM:</strong> Sequential models (Recurrent Neural Networks, Long Short-Term Memory) that process text step-by-step, good for learning long-range dependencies.</li>
                            <li><strong>Attention Mechanism:</strong> A key innovation allowing a model to focus on the most relevant parts of an input sequence.</li>
                            <li><strong>The Transformer:</strong> A non-sequential model based entirely on Self-Attention and Multi-Headed Attention, enabling parallel training and superior context understanding.</li>
                            <li><strong>Pre-trained Models:</strong> Models like BERT and ROBERTa are trained on massive datasets and then "fine-tuned" for specific tasks.</li>
                        </ul>
                    </div>
                    <!-- Column 2 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Key Applications</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Information Extraction (IE):</strong> Pulling structured data (names, dates) from text.</li>
                            <li><strong>Information Retrieval (IR):</strong> Finding relevant documents (how search engines work).</li>
                            <li><strong>Semantic Search:</strong> Searching based on *meaning* and *intent*, not just keywords.</li>
                            <li><strong>Summarization:</strong> Extractive (copying) vs. Abstractive (generating) summaries.</li>
                            <li><strong>Chatbots & NLU/NLG:</strong> Understanding user input (NLU) and generating human-like responses (NLG).</li>
                            <li><strong>Machine Translation:</strong> Automatically translating between languages (e.g., Neural Machine Translation).</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Unit 5: Probabilistic & Statistical NLP -->
            <section id="unit-5" class="bg-white p-8 rounded-xl shadow-lg">
                <h2 class="text-3xl font-bold text-gray-900 mb-6">Unit 5: Probabilistic & Statistical NLP</h2>
                <p class="text-lg text-gray-700 mb-6">This unit covered the foundational methods of using probability and statistics to model the uncertainty and patterns inherent in human language.</p>
                <div class="grid md:grid-cols-2 gap-6">
                    <!-- Column 1 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Core Concepts</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Probabilistic Models:</strong> Using probability to predict outcomes, like a Language Model (LM) predicting the next word based on n-grams (unigram, bigram).</li>
                            <li><strong>Statistical Approaches:</strong> Applying classic machine learning algorithms (like Naive Bayes, Hidden Markov Models) to NLP tasks.</li>
                            <li><strong>Sequence Labeling:</strong> A core task of assigning a label to each token in a sequence, such as Part-of-Speech (POS) Tagging or Named Entity Recognition (NER).</li>
                        </ul>
                    </div>
                    <!-- Column 2 -->
                    <div class="bg-gray-50 p-6 rounded-lg">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">Text Representation & Similarity</h3>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><strong>Text Similarity:</strong> Calculating how "alike" two texts are using measures like Jaccard Similarity, Euclidean Distance, and Cosine Similarity.</li>
                            <li><strong>Embeddings:</strong> Representing words (CBOW, Skip-gram) and sentences as dense vectors to feed into statistical models.</li>
                            <li><strong>Neural Models:</strong> Using RNNs and LSTMs as advanced methods for modeling sequential data, building upon statistical foundations.</li>
                        </ul>
                    </div>
                </div>
            </section>

        </div>
    </main>

    <!-- Footer -->
    <footer class="bg-gray-800 text-gray-300 p-8 text-center">
        <p>&copy;2025 Rohan S - NLP Course Portfolio</p>
        <p class="mt-2 text-sm">NLP 21CSE356T</p>
    </footer>

</body>
</html>

